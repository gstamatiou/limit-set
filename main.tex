\documentclass{report}

% Packages for math symbols and equations
\input{packages}
\input{commands}

% Title page information
\title{Limit sets of Anosov representations}
\author{Giorgos}
\date{\today}

\begin{document}

\maketitle

\tableofcontents

\chapter{Introduction}
\section{Lie group preliminaries}
We fix the Cartan subalgebra $\mathfrak a$ of $\SL(d,\mathbb R)$:
\[
    \mathfrak a = \left\{
        \diag(\alpha_1, \ldots, \alpha_d) : \alpha_1 + \cdots \alpha_d = 0
    \right\}
\]
and the Weyl chamber $\mathfrak a^+$ of $\SL(d,\mathbb R)$
\[
    \mathfrak a^+ = \left\{
        \diag(\alpha_1, \ldots, \alpha_d) : \alpha_1 \geq \cdots \geq \alpha_d
    \right\}.
\]
Denoting with $K = \SO(d, \mathbb R), A^+ = e^{\mathfrak a^+} $, we have the Cartan decomposition:
\begin{align*}
    \mathfrak{sl}(d, \mathbb R) &\rightarrow K \times A^+ \times K\\
    g &\mapsto (k_g, a_g, l_g) 
\end{align*}
such that $g = k_g a_g l_g$.
In particular $a_g = \diag(\sigma_1(g), \ldots, \sigma_d(g))$ with $\sigma_1 \geq \cdots \geq \sigma_d(g)$,
where $\sigma_i(g)$ is the $i$-th singular value of $g$, i.e.\ eigenvalue of $g^t \cdot g$.

We will use the spaces
\[
    U_p(g) = \mathbb R u_1(g) \oplus \cdots \oplus \mathbb R u_p(g)   
\]
where $u_i(g) = k_g \cdot e_i$.
One can easily show that the decomposition
\[
    g^{-1} \cdot U_p(g) \oplus U_{d-p}(g^{-1})
\]
is orthogonal with respect to the standard inner product and that
$u_p(g^{-1}) = l_g^{-1} e_{d-p+1}(g).$
\section{Limit set preliminaries}
\begin{definition}
For $p \in \{2, \ldots, d\}, s\in \mathbb R $
and $g \in SL(d, \mathbb R)$ 
we denote with $\tilde \Psi_s^p(g), \Psi_s^p(g): \SL(d, \mathbb R) \to \mathbb R$ the functional:
\begin{align*}
\Psi_s^p(g) &= 
    \alpha_{12}(a(g)) + \cdots + \alpha_{1(p-1)}(a(g)) + (s - (p-2))\alpha_{1p}(a(g))\\
\tilde \Psi_s^p(g) &= 
    \left( \frac{\sigma_2}{\sigma_1}\cdots\frac{\sigma_{p-1}}{\sigma_1}(g)\right) 
    \left( \frac{\sigma_{p-1}}{\sigma_1}(g) \right)^{s - (p-2)}
\end{align*}
\end{definition}
\begin{remark}
    We have $\alpha_{ij}(a) = a_i - a_j, a_i(g) = \log (\sigma_i(g))$ and 
    \[
        \Psi_s^p(g) = \log \tilde \Psi_s^p(g)
    \]
and that
\begin{align*}
    \min_{p \in \llbracket 2, d \rrbracket} 
    \left\{ 
        \sum_{|\gamma| = T} 
            \frac{\sigma_2}{\sigma_1}\cdots\frac{\sigma_{p-1}}{\sigma_1}(g) 
            \left( \frac{\sigma_{p-1}}{\sigma_1}(g) \right)^{s - (p-2)}
    \right\} = 
    \sum_{|\gamma| = T} e^{-\max\limits_{p \in \llbracket 2, d \rrbracket} \Psi_s^p(g)}
\end{align*}
\end{remark}

\begin{remark}
For any $g \in \SL(d, \mathbb R)$ we have that:
\[
    \max_{p \in \llbracket 2, d \rrbracket} \Psi_s^p(g) = \Psi_s^{p_0}(g) \text{ for } s \in [p_0 - 2, p_0 -1].
\]
Indeed, a quick calculation shows that for $s \geq 0$ and $p \in \llbracket 2, d \rrbracket$:
\[
    \Psi_s^p(g) \leq \Psi_s^p(g) \text{ if and only if } s \geq p-1.
\]
and that equality holds in the case $s = p - 1$.
Thus for $s \in [p - 2, p-1]$ we have that
\begin{align*}
    s \geq p-2, \ldots, 1 &\text{ implies that } \Psi_s^p(g) \geq \ldots \geq \Psi_s^{2}(g)\\
    s \leq p, \ldots, d-1 &\text{ implies that } \Psi_s^p(g) \leq \ldots \leq \Psi_s^d(g)
\end{align*}
Another way to see this (refer to \cref*{fig:max}) is to note that $\Psi_s^2(g), \cdots, \Psi_s^d(g)$ is a sequence of functions that are affine in $s$, with slopes $\alpha_{12}(g) \leq \cdots \leq \alpha_{1d}(g)$ and that they satisfy $\Psi_1^2(g) = \Psi_2^2(g), \Psi_2^3(g) = \Psi_3^4(g) \ldots, \Psi_{d-2}^{d-1}(g) = \Psi_{d-2}^d(g)$.
\begin{figure}[h]
    \centering
    \includegraphics[width=0.4\textwidth]{max.jpg}
    \caption{Visual illustration that $\max_p\Psi_s^p(g) = \Psi_s^{p_0}(g) \text{ for } s \in [p_0 - 2, p_0 -1]$.}
    \label{fig:max}
\end{figure}    
\end{remark}


The following definition comes from \cite{ledrappier_dimension_2023}, in the special case of projective Anosov representations ($P = {1}$):
\begin{definition}
    For $s \geq 0$ we consider the Falconer functional $F_s : \SL(d, \mathbb R) \to \mathbb R$ by:
    \[
        F_s(g) = \min 
        \left\{
            \sum_{j=2}^d s_j \alpha_{1j}(a(g)) : s_j \in (0,1], \sum_{j=2}^d s_j = s 
        \right\},
    \]
    and define the Falconer dimension $\dim_F(\rho)$ of $\rho$ to be its critical exponent:
    \[
        \dim_F(\rho) = \inf
        \left\{
            s > 0: \sum_{\gamma \in \Gamma} e^{-F_s(\rho(\gamma))} < \infty
        \right\}.
    \]
\end{definition}

\begin{remark}
    Using elementary computations one may prove that for all $s \geq 0$:
    \[
        F_s(g) = \max_{p \in \llbracket 2, d \rrbracket} \Psi_s^p(g)
    \]
\end{remark}

\begin{definition}
Let $\rho: \Gamma \to \SL(d, \mathbb R)$ be a linear representation and $p \in \llbracket 1, d-1 \rrbracket$.
We say that $\rho$ is $p$-Anosov if there exist constants $\mu, C>0$ such that for all $\gamma \in \Gamma$:
\[
    \frac{\sigma_{p+1}}{\sigma_p}(\rho(\gamma)) \leq C e^{-\mu |\gamma|}.
\]
One can show that in that case there exist equivariant continuous maps $\xi^p: \hat \Gamma \to \mathcal G_p(\mathbb R^d) , \xi^{d-p}: \hat \Gamma \to \mathcal G_{d-p}(\mathbb R^d)$ that are transverse and restrict to
\[
    \xi^p(\gamma) = U_p(\rho(\gamma)), \xi^{d-p}(\gamma) = U_{d-p}(\rho(\gamma))
\]
for $\gamma \in \Gamma$, where $U_p(\gamma), U_{d-p}(\gamma)$ denote the flags 
\todo{Figure out what this exactly means}
corresponding to  $\rho(\gamma)$.
\end{definition}
\chapter{Upper bound}
\section{Proof of bound}
\begin{lemma}[Upper bound for dimension]\label{lem:upper_bound}
Let $\rho: \Gamma \to \SL(d, \mathbb R)$ be a projective Anosov representation. 
Then:
\[
    \dim_H(\xi^1 (\partial \Gamma) ) \leq
    \inf 
    \left\{ 
        s :  
        \sum_{|\gamma| = T} e^{-F_s(\rho(\gamma))}  < \infty
    \right\}.
\]
\end{lemma}
\begin{remark}
    The idea of the proof of \cref*{lem:upper_bound} is to find a covering whose Hausdorff content is dominated by the Dirichlet series of some functional $\Psi_s^p$, which will in turn imply that $\dim_H(\xi^1(\partial \Gamma)) \leq h_\rho(\Psi^p) $.
    Choosing then the most "effective" cover (i.e.\ the one which yields the smallest Hausdorff content up to a constant) we obtain that
    \[
        \dim_H(\xi^1(\partial \Gamma)) \leq h_\rho(\max_p \Psi^p)
    \]
    To obtain this we first cover $\xi^1(\partial \Gamma)$ by the bassins of attraction $\rho(\gamma) \cdot B_{\alpha_1, \alpha} (\rho(\gamma))$ for $\gamma \in \Gamma$ satisfying $|\gamma| = T$.
    Then we cover each bassin by an ellipsoid of axes lengths
    \[
        \frac{1}{\sin(\alpha)} \frac{\sigma_2}{\sigma_1}(\rho(\gamma)), \ldots, 
        \frac{1}{\sin(\alpha)} \frac{\sigma_d}{\sigma_1}(\rho(\gamma)).
    \]
    Finally we cover each ellipsoid by balls of some fixed radius $r>0$.
    It can be shown by comparing the series appearing in the Hausdorff content of each resulting cover that the most "effective" choice of $r$ depends only on the Hausdorff exponent $s > 0$ and in any case will be to have $r$ equal (up to a constant) to the the length of an axis of the ellipsoid, i.e.\
    \[
        r \in \left\{
            \frac{1}{\sin(\alpha)} \frac{\sigma_2}{\sigma_1}(\rho(\gamma)), \ldots, 
            \frac{1}{\sin(\alpha)} \frac{\sigma_d}{\sigma_1}(\rho(\gamma)).    
        \right\}
    \]
    In particular, when $s \in [p-2, p-1]$, the most effective choice is $r = \sigma_p(\rho(\gamma))/\sigma_1(\rho(\gamma))$, whose Hausdorff content is dominated by the Dirichlet series of $\Psi_s^p$.
\end{remark}

\begin{proof}[Proof of \cref*{lem:upper_bound}]
Let $p \in \llbracket 2, d \rrbracket$.
Then using \cref{prop:basin_covering}, \cref{lem:boundary_covering}, and \cref{lem:ellipsoid_covering} we have that for $T>0$ large enough, $\xi^1(\partial \Gamma)$ is covered by the family
\[
    \mathcal U_T = \left\{ \rho(\gamma) B_{\alpha_1, \alpha}(\rho(\gamma)) : |\gamma| = T \right\},
\]
and that each basin $\rho(\gamma) B_{\alpha_1, \alpha}(\rho(\gamma))$ is in turn covered by
\[
    2^{2p+1} \cdot \frac{\sigma_p(g)^{p-2}}{\sigma_2(g) \cdots \sigma_{p-1}(g)}
\]
many balls of radius
\[
    \sqrt{d} \frac{1}{\sin \alpha} \frac{\sigma_p(g)}{\sigma_1(g)}.
\]
By the definition of the Hausdorff measure, for $s \geq 0$:
\begin{align*}
    \mathcal H^s(\xi^1(\partial \Gamma)) &\leq
    \sum_{|\gamma| = T}
        2^{2p+1} \cdot 
        \frac{\sigma_2(\rho(\gamma))}{\sigma_1(\rho(\gamma))} \cdots 
            \frac{\sigma_{p-1}(\rho(\gamma))}{\sigma_1(\rho(\gamma))}
        \left(
            \frac{\sigma_p(\rho(\gamma))}{\sigma_1(\rho(\gamma))}
        \right)^{-(p-2)}
        \left(
            \sqrt{d} \frac{1}{\sin \alpha} \frac{\sigma_p(\rho(\gamma))}{\sigma_1(\rho(\gamma))}
        \right)^s =\\
        &=
        2^{2p+1} \cdot \left( \frac{\sqrt{d}}{\sin \alpha}\right)^s  
        \sum_{|\gamma| = T} 
        \frac{\sigma_2(\rho(\gamma))}{\sigma_1(\rho(\gamma))} \cdots 
            \frac{\sigma_{p-1}(\rho(\gamma))}{\sigma_1(\rho(\gamma))}
        \left(
            \frac{\sigma_p(\rho(\gamma))}{\sigma_1(\rho(\gamma))}
        \right)^{s-(p-2)} =\\
        &=
        2^{2p+1} \cdot \left( \frac{\sqrt{d}}{\sin \alpha}\right)^s  
        \sum_{|\gamma| = T}
        e^{-\left( \alpha_{1 2} + \ldots + \alpha_{1 (p-1)} + (s - (p-2))\alpha_{1 p} \right)\rho(\gamma)}\\
        &=
        2^{2p+1} \cdot \left( \frac{\sqrt{d}}{\sin \alpha}\right)^s  
        \sum_{|\gamma| = T}
        e^{-\Psi_s^p(\rho(\gamma))}
\end{align*}
and thus
\begin{align*}
    \mathcal H^s(\xi^1(\partial \Gamma)) \leq
    2^{2p+1} \cdot \left( \frac{\sqrt{d}}{\sin \alpha}\right)^s
    \sum_{|\gamma| = T}
    e^{-\max_p \Psi_s^p(\rho(\gamma)) }\lesssim \sum_{|\gamma| = T} e^{-F_s(\rho(\gamma))}.
\end{align*}
To see that the above implies the upper bound, consider some $s > \dim_F(\rho)$.
By the definition of the Falconer dimension, this implies that the Dirichlet series corresponding to the Falconer functional converges:
\[
    \sum_{\gamma \in \Gamma} e^{-F_s(\rho(\gamma))} < \infty
\]
and in particular
\[
    \mathcal H^s(\xi^1(\partial \Gamma)) \leq 
    \lim_{T \to \infty} e^{-F_s(\rho(\gamma))} = 0.
\]
\end{proof}

\section{Lemmata}
\begin{definition}
    Let $V$ be a finite-dimensional $\mathbb R$-vector space.
    We consider a decomposition
    \[
        V = \mathbb R u_1 \bigoplus \cdots \bigoplus \mathbb R u_d
    \] 
    be a direct decomposition that is orthogonal with respect to a fixed inner-product over $V$.
    Given $\beta_2 \geq \ldots \beta_d > 0$, we define an ellipsoid with axes $u_1 \oplus u_p(g)$ and lengths $\beta_p$ to be the image of
    \[
        \left\{
            v = \sum_1^d v_i u_i\in V : \sum_2^d \left( \frac{v_j}{\beta_j} \right)^2 \leq 1
        \right\}
    \]
    through the projection $ V \to \mathbb P (V)$.
\end{definition}
\begin{figure}[h]
    \centering
    \includegraphics[width=0.4\textwidth]{ellipsoid.jpg}
    \caption{Depiction in $\mathbb R^3$ of an ellipsoid of $\mathbb P(\mathbb R^2)$}
    \label{fig:ellipsoid}
\end{figure}    

The following aims to be something along the lines of \cite*[Lemma 2.4]{pozzetti_anosov_2023}:
\begin{lemma}\label{lem:angle}
    Let $\rho: \Gamma \to \SL(d, \mathbb R)$ be a projective Anosov representation.
    For $\alpha > 0$ small enough, there exists $L>0$ such that for any geodesic ray $(a_j)_j$ through $e$ we have:
    \[
        \angle(U_1(\rho(a_i)), U_1(\rho(a_0))) > \alpha
    \]
    when $|a_i|, |a_0| > T$.
\end{lemma}
\begin{proof}
Assume the contrary for the shake of contradiction.
Then (see Figure \ref{fig:angle} ) for each $n>0$ there exists a geodesic ray  $a^n$ through $e$ such that 
\[
    |a_n^n|, |a_0^n| > n \text{ and }
    \angle(U_1(\rho(a_n^n)), U_1(\rho(a_0^n))) < \frac{1}{n}.
\]
Due to compactness of $\partial \Gamma$ we may assume (up to a subsequence) that
$a^n \to x$ in $\partial \Gamma$ for some $x \in \partial \Gamma$.
Then 
\todo{Not sure if this is true.}
$a^n_n, a_0^n \to x$ in $\hat \Gamma$ which implies
\[
    \angle (\xi^1(x), \xi^{d-1}(x)) = 0
\]
using the fact that the limit maps $\xi^1, \xi^{d-1}$ are continuous, which contradicts their tranversality.
\end{proof}
\begin{figure}[h]
    \centering
    \includegraphics[width=0.3\textwidth]{angle.jpg}
    \caption{Situation in \cref{lem:angle}}
    \label{fig:angle}
\end{figure}    

The following is \cite[Proposition 3.5]{pozzetti_anosov_2023}.
\begin{lemma}\label{lem:boundary_covering}
Let $\rho: \Gamma \to SL(d, \mathbb R)$ be projective Anosov.
Then for $\alpha > 0$ small enough, there exists some $T_0 > 0$ such that for all $T \geq T_0$ the family
\[
    \mathcal U_T = \left\{ \rho(\gamma) B_{\alpha_1, \alpha}(\rho(\gamma)) : |\gamma| = T \right\}
\]
is an open covering of $\xi^1(\partial \Gamma)$.
\end{lemma}
\begin{proof}
    Let $\alpha, T > 0$ be as in the statement of \cref*{lem:angle} and $x \in \partial \Gamma$ be represented by a geodesic ray $(\gamma_j)_{j\geq 0}$ starting from $e$.
    Then $(\gamma_T^{-1} \gamma_j)_j$ is a geodesic ray starting from $(\gamma_T)^{-1}$ that passes through $e$, so
    \[
        \angle (U_1(\rho(\gamma_T^{-1}\gamma_j)), U_{d-1}(\rho(\gamma_T^{-1}))) > \alpha
    \]
    as implied by \cref*{lem:angle}.
    Taking the limit $j \to \infty$ and using the equivariance of the limit map, we obtain
    \[
        \angle (\rho(\gamma_T^{-1})\xi^1(x), U_{d-1}(\rho(\gamma_T^{-1}))) > \alpha
    \]
    and thus $\xi^1(x) \in \rho(\gamma_T) \cdot B_{\alpha_1, \alpha}(\rho(\gamma_T))$.
\end{proof}

The following is \cite[Proposition 3.8]{pozzetti_anosov_2023}.
\begin{proposition}\label{prop:basin_covering}
For each $g\in \SL(d, \mathbb R), \alpha > 0$, 
the basin of attraction $g \cdot B_{\alpha_1, \alpha}(g)$ lies in the ellipsoid with axes $u_1(g) \oplus u_p(g)$ with lengths
\[
    \frac{1}{\sin \alpha} \cdot \frac{\sigma_p(g)}{\sigma_1(g)}
\]
\end{proposition}
\begin{proof}
Using the definition of the basin of attraction (see \cref*{fig:projection} ), we have that $w = w_1 u_1(g^{-1}) + \cdots + w_d u_d(g^{-1}) \in B_{\alpha_1, \alpha}(g)$ if and only if
\[
    w_d^2 \geq (\sin \alpha)^2 \sum_1^d w_i^2.
\]
Considering now some $v = v_1 u_1(g) + \cdots + v_d u_d(g) \in g \cdot B_{\alpha_1, \alpha}(g)$
we have that
\begin{align*}
    w = g^{-1} v &= v_1 \sigma_1(g)^{-1} l_g^{-1} e_1(g) + \cdots v_d \sigma_d(g)^{-1} l_g^{-1} e_d(g)\\
    &= v_1 \sigma_1(g)^{-1} u_{d}(g^{-1}) + \cdots v_d \sigma_d(g)^{-1} u_1(g^{-1})
\end{align*}
where we used that $u_p(g^{-1}) = l_g^{-1} e_{d+1-p}$.
Hence
\[
    \sigma_1(g)^{-2} \cdot v_1^2 \geq (\sin a)^2 \sum_1^d \sigma_i(g)^{-2} v_i^2.
\]
\end{proof}
\begin{figure}[h]
    \centering
    \includegraphics[width=0.4\textwidth]{projection.jpg}
    \caption{Aid for \cref{prop:basin_covering}}
    \label{fig:projection}
\end{figure}

The following is \cite[Lemma 3.7]{pozzetti_anosov_2023}:
\begin{lemma}\label{lem:ellipsoid_covering}
For any $p \in \llbracket 2, d \rrbracket$, an ellipsoid in $\mathbb P(\mathbb R^d)$ of axes lengths $\beta_2, \cdots, \beta_d$ is covered by
\[
    2^{2p + 1} \frac{\beta_2 \cdots \beta_{p-1}}{\beta_p^{p-2}}
\]
many balls of radius $\sqrt{d} \beta_p$.
\end{lemma}

The following can be found in \cite[Proposition 3.3]{pozzetti_anosov_2023}:
\begin{proposition}
    Let $\rho: \Gamma \to SL(d, \mathbb R)$ be projective Anosov and $\alpha > 0$
    Then there exist $c_0, c_1 > 0$ that depends only on $\alpha$ and $\rho$ such that for all $\gamma \in \Gamma$:
    \[
        (\xi^1)^{-1}(B_{\alpha_1, \alpha}(\rho(\gamma))) \subseteq C_{c_0,c_1}^\infty(\gamma)
    \]
\end{proposition}
\begin{proof}
    We begin by noting that it suffices to show this for all but finitely many $\gamma \in \Gamma$, since then we may alter the constants to satisfy the wanted inclusion also for the finitely many remaining $\gamma \in \Gamma$. Given this, we shall assume that $|\gamma| \geq l_0$ where $l_0 > 0$ is such that $Ce^{-\mu l_0} < 1$ and $C, \mu > 0$ are the constants appearing in the definition of the Anosov property of $\rho$..

    Suppose $x \in \partial \Gamma$ such that $\xi^1(x) \in B_{\alpha_1, \alpha}(\rho(\gamma))$, and consider a geodesic ray $a_j \to x$ starting from $a_0 = e$.
    To prove the result, it suffices to find constants $c_0, c_1$ independent of $\gamma$ and a ($c_0$, $c_1$)-quasi-geodesic from $\gamma^{-1}$ to $x$ that passes through $e$ and stays at a bounded distance from $(a_j)_{j=0}^\infty$

    Using \cite[Proposition 2.5]{pozzetti_anosov_2023} we have that
    $d(\xi^1(a_j), U_{d-1}(\rho(\gamma^{-1}))) \leq C e^{-\mu j}$, 
    so there exists some $L>0$ that depends only on $\alpha$ 
    such that for all $j\geq L: U_1(\rho(a_j))\in B_{\alpha_1, \alpha}(\rho(\gamma))$ and in particular
    \[
        d(\xi^1(a_j), \gamma^{-1}) = d(U_1(\rho(a_j)), U_1(\rho(\gamma^{-1}))) \geq 
        d(U_1(\rho(a_j)), U_{d-1}(\rho(\gamma^{-1}))) > \sin\alpha.
    \]
    Along with the uniform continuity of $\xi^1: \Gamma \cup \partial \Gamma \to \mathbb P(\mathbb R^d)$ this implies there exists some $\alpha' > 0$ and $L>0$ such that for all $j\geq L$:
    \[
        d(a_j, \gamma^{-1}) \geq \alpha'.
    \]
    Upon considering a large $L$, we may also assume that $|a_L| = L > l_0$. Note that both $\alpha'$ and $L$ do not depend on each $\gamma$ but only on $\rho$ and $\alpha$.

    Using some geometric group theory, we can show that for all $j \geq L$
    \[
        d(\gamma^{-1}, a_j) > \alpha' \Rightarrow
        d([\gamma^{-1}, a_j], e) < \alpha''
    \]
    for some $\alpha''$ that depends only on $\Gamma$ and $\alpha'$, where $[a_j, \gamma^{-1}]$ denotes the geodesic segment connecting $\gamma^{-1}$ and $a_j$.

    Consider the concatenation $(a_j')_{j=L-K}^\infty$ of $[\gamma^{-1},a_L]$ and $[a_L, x]$.
    To find quasi-geodesic-constants that are uniform in $\gamma$, we note that for any $c_0 \geq 1, c_1 \geq 0$:
    \[
        c_0^{-1} |i - j| - c_1 \leq d(a_i', a_j') = d(a_i, a_j) \leq d(a_i) c_0^ |i - j| + c_1 
        \text{ when } i,j \geq L \text{ or } i,j \leq L
    \]
    and that the upper bound follows trivially by the triangle inequality. 
    
    For the lower bound we proceed in two steps. 
    First we bound the distance of $\gamma^-1 = a_{L-K}'$ to $a_{L+j}$ for $j\geq 0$:
    \begin{align*}
        d(a_{L-K}', a_{L+j}') 
        &\geq \nu (|a_{L+j}| - |\gamma^{-1}|) - c_0' -c_1'|\log(d(U_1(\rho(a_{L+j})), U_1(\rho(\gamma^{-1}))))| \geq\\
        &\geq \nu((L+j) + (K-L)) - c_0' -c_1'|\log(\sin a)| \geq\\
        &= c_0^{-1} (j+K) - c_1
    \end{align*}
    for $c_0 = \nu^{-1}, c_1 = c_0' + c_1'|\log(\sin \alpha)|$.
    The first inequality comes from \cite[Lemma 3.9]{pozzetti_anosov_2023}. For the second inequality we estimate $|\gamma^{-1}|$ from below using the triangle inequality.
    We are now ready to show that the concatenation $(a_j')_j$ is indeed a ($c_0$, $c_1$)-geodesic:
    \begin{align*}
        d(a_{L+j}, a_{L-i}) &\geq d(a_{L+j},a_{L_K}) - d(a_{L_K}, a_{L-i}) \geq
        c_0^{-1} (j+K) - c_1 - (K - i) \geq\\
        &\geq c_0^{-1} (j+i) - c_1.
    \end{align*}

    Note however that $(a_j')$ does not necessarily lie in $C_\infty^{c_0, c_1}$ since it may not pass through $e$.
    For this reason we some $L - K \leq i_0\leq L$ such that $|a_{i_0}| < \alpha''$, the existence of which is guaranteed by the fact that $d([\gamma^{-1}, a_L], \epsilon) < \alpha''$.
    We then consider alter $(a_j')$ at $i_0$ so that it passes through $e$ to obtain 
    \begin{align*}
        a_j''=
        \begin{cases}
            a_j & \text{for } j\neq i_0 \\
            e & \text{for } j = i_0
        \end{cases}      
    \end{align*}
    which is a ($c_0, c_1 + \alpha''$)-quasigeodesic passing from $e$ and converging to $x$.
\end{proof}
\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{cone.jpg}
\end{figure}    
\printbibliography

\end{document}